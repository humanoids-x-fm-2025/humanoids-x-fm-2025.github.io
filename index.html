<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Humanoids 2025 Workshop</title>
    <link rel="stylesheet" href="styles.css" />
    <link href="https://fonts.googleapis.com/css2?family=Outfit:wght@400;600;800&display=swap" rel="stylesheet">

    <!-- Open Graph / Social Media Preview -->
    <meta property="og:title" content="Humanoids 2025 Workshop" />
    <meta property="og:description" content="Bridging Humanoid Robotics and Foundation Models: Embodied Intelligence and AI Integration · October 2, 2025 · COEX, Seoul" />
    <meta property="og:image" content="https://humanoids-x-fm-2025.github.io/assets/sticker_nobg.png" />
    <meta property="og:url" content="https://humanoids-x-fm-2025.github.io/" />
    <meta property="og:type" content="website" />

    <!-- Twitter Card (optional but recommended) -->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Humanoids 2025 Workshop" />
    <meta name="twitter:description" content="Join us in Seoul for a full-day workshop on Humanoid Robotics and Foundation Models." />
    <meta name="twitter:image" content="https://humanoids-x-fm-2025.github.io/assets/sticker_nobg.png" />
</head>
<body>
    <header>
        <nav class="container">
            <div class="logo">
                <img src="./assets/sticker_nobg.png" alt="Humanoids 2025 Logo" class="logo-img" />
                Bridging Humanoid Robotics and Foundation Models Workshop
            </div>
            <ul class="nav-links">
                <li><a href="#about">Objective and Scope</a></li>
                <li><a href="#speakers">Speakers</a></li>
                <li><a href="#organizers">Organizers</a></li>
                <li><a href="#program">Program</a></li>
                <li><a href="#cfp">Call for Posters</a></li>
                <li><a href="#contact">Contact</a></li>
            </ul>
        </nav>
    </header>

    <section class="hero">
        <div class="overlay"></div>
        <img src="./assets/logo_landscape.png" alt="Humanoid Seoul" class="hero-bg" />
        <div class="hero-text container">
            <h1>Bridging Humanoid Robotics and Foundation Models: Embodied Intelligence and AI Integration</h1>
            <p>October 2, 2025 · COEX, Seoul</p>
            <p style="font-size:0.9rem;">Full-day Workshop</p>
        </div>
    </section>

    <main class="container">
        <section id="about" class="section">
            <h2>Objective and Scope</h2>
            <p> The integration of foundation models, such as Large Language Models (LLMs), Vision-Language Models
                (VLMs), Vision-Language-Action Models (VLAMs), and other multimodal architectures, has the potential to
                fundamentally reshape how humanoid robots perceive, reason, act, and interact in the world.
                Until recently, general-purpose humanoid robots were constrained by the limited scalability of
                traditional planning, control, and perception pipelines. These robots, designed to understand
                instructions, adapt to novel environments, and engage in human-like interactions, often struggled to
                meet the flexibility required for general use. Foundation models offer a major step forward by enabling
                abstract reasoning, grounding through multi-modal inputs, and fast generalization across tasks and
                domains.
                However, integrating these models into humanoid robots presents open challenges. Questions remain about
                grounding abstract knowledge into sensorimotor data, combining model-based control with learned
                representations, ensuring safety and interpretability, and enabling embodied models to interact socially
                and linguistically with humans.
                Humanoid platforms, ranging from full-body anthropomorphic robots to more abstract bimanual systems, are
                especially well-suited for this line of research. Their structural similarity to humans and versatility
                make them ideal for exploring foundation model grounding, physical reasoning, and social interaction in
                human environments.
                This workshop is designed to promote collaboration between academic researchers and industry
                practitioners. The program will feature keynote talks, a cross-sector panel discussion, and a call for
                contributed presentations, with a particular focus on emerging research at the intersection of humanoid
                robotics and foundation models.
                By fostering this convergence, the workshop aims to build a roadmap toward generalizable, human-aligned,
                and socially capable humanoid systems powered by foundation models.
            </p>
            <h4>Topics</h4>

            <ul class="topics-list">
                <li><strong>Models for Humanoid Robotics:</strong> Use of large pre-trained language and vision-language
                    models for planning, decision-making, and control in humanoid systems</li>
                <li><strong>Multimodal Perception and World Modeling:</strong> Leveraging VLMs for scene understanding,
                    object grounding,
                    spatial awareness, and physical commonsense reasoning</li>
                <li><strong>Policy Learning with Foundation Models:</strong> Language-guided reinforcement and imitation
                    learning, as
                    well as model-based control augmented by LLMs</li>
                <li><strong>Human-Robot Interaction and Social Intelligence:</strong> Social reasoning, linguistic
                    interaction, and
                    collaborative behavior in human-centered environments</li>
                <li><strong>Safety, Interpretability, and Human Alignment:</strong> Ensuring safe, transparent, and
                    aligned behavior in
                    LLM- or VLM-driven humanoid systems</li>
                <li><strong>Simulation, Evaluation, and Benchmarks:</strong> Tools and protocols for benchmarking
                    embodied foundation
                    models in humanoid tasks, including real-world and simulated settings</li>
                <li><strong>Applications in Complex Environments:</strong> Household assistance, healthcare, industrial
                    tasks, mobile
                    manipulation, and human-facing applications involving physical and social complexity</li>
            </ul>

        </section>

        <section id="speakers" class="section">
            <h2>Speakers</h2>
            <p> Full List of speakers coming soon! </p>
            <div class="profile-grid">
                <div class="card">
                    <div class="profile">
                        <div class="circle-img" style="background-image: url('assets/jp.jpg');"></div>
                        <p><strong>Jan<br>Peters</strong><br>TU Darmstadt | DFKI </p>
                    </div>
                </div>

                <div class="card">
                    <div class="profile">
                        <div class="circle-img" style="background-image: url('assets/kg.jpeg');"></div>
                        <p><strong>Keerthana<br> Gopalakrishnan</strong><br>Google Deepmind</p>
                    </div>
                </div>
                <div class="card">
                    <div class="profile">
                        <div class="circle-img" style="background-image: url('assets/rj.jpeg');"></div>
                        <p><strong>Ryan <br> Julian</strong><br>Google Deepmind</p>
                    </div>
                </div>
                <div class="card">
                    <div class="profile">
                        <div class="circle-img" style="background-image: url('assets/kw.png');"></div>

                        <p><strong>Kento <br>Kawaharazuka </strong><br>The University of Tokyo</p>
                    </div>
                </div>
                <div class="card">
                    <div class="profile">
                        <div class="circle-img" style="background-image: url('assets/xw.jpg');"></div>
                        <p><strong>Xiaolong <br> Wang</strong><br> UC San Diego</p>
                    </div>
                </div>
                <div class="card">
                    <div class="profile">
                        <div class="circle-img" style="background-image: url('assets/rq.jpeg');"></div>
                        <p><strong> Ri-Zhao (Roger) Qiu </strong><br>UC San Diego</p>
                    </div>
                </div>
                <div class="card">
                    <div class="profile">
                        <div class="circle-img" style="background-image: url('assets/jj.jpg');"></div>
                        <p><strong> Joel Jang </strong><br>Nvidia GEAR Lab</p>
                    </div>
                </div>
                <div class="card">
                    <div class="profile">
                        <div class="circle-img" style="background-image: url('assets/rl.jpg');"></div>
                        <p><strong> Rudolf Lioutitkov </strong><br>Nvidia GEAR Lab</p>
                    </div>
                </div>
            </div>
        </section>


        <section id="organizers" class="section">
            <h2>Organizers</h2>
            <div class="profile-grid">
                <div class="card">
                    <div class="profile">
                        <div class="circle-img" style="background-image: url('assets/dt.jpg');"></div>
                        <p><strong>Dionis Totsila</strong><br>INRIA</p>
                    </div>
                </div>

                <div class="card">
                    <div class="profile">
                        <div class="circle-img" style="background-image: url('assets/si.jpg');"></div>
                        <p><strong>Serena Ivaldi</strong><br>INRIA</p>
                    </div>
                </div>

                <div class="card">
                    <div class="profile">
                        <div class="circle-img" style="background-image: url('assets/ta.JPG');"></div>
                        <p><strong>Tamim Asfour</strong><br>KIT</p>
                    </div>
                </div>


                <div class="card">
                    <div class="profile">
                        <div class="circle-img" style="background-image: url('assets/kg.jpeg');"></div>
                        <p><strong>Keerthana Gopalakrishnan</strong><br>Google Deepmind</p>
                    </div>

                </div>
                <div class="card">
                    <div class="profile">
                        <div class="circle-img" style="background-image: url('assets/rj.jpeg');"></div>
                        <p><strong>Ryan Julian</strong><br>Google Deepmind</p>
                    </div>
                </div>
            </div>

        </section>


        <section id="program" class="section">
            <h2>Preliminary Program</h2>
            <table class="program-table">
                <tr>
                    <td class="sched_time">09:00 - 09:30</td>
                    <td class="sched_speaker">
                        <strong>Welcome & Introduction</strong>
                    </td>
                </tr>
                <tr>
                    <td class="sched_time">09:30 - 10:00</td>
                    <td class="sched_speaker">
                        <strong>Speaker 1</strong>
                    </td>
                </tr>
                <tr>
                    <td class="sched_time">10:00 - 10:30</td>
                    <td class="sched_speaker">
                        <strong>Spotlight Presentations</strong>
                    </td>
                </tr>
                <tr>
                    <td class="sched_time">10:30 - 11:00</td>
                    <td class="sched_speaker">
                        <strong>Coffee Break</strong>
                    </td>
                </tr>
                <tr>
                    <td class="sched_time">11:00 - 11:30</td>
                    <td class="sched_speaker">
                        <strong>Speaker 2</strong>

                    </td>
                </tr>
                <tr>
                    <td class="sched_time">11:30 - 12:00</td>
                    <td class="sched_speaker">
                        <strong>Speaker 3</strong>

                    </td>
                </tr>
                <tr>
                    <td class="sched_time">12:00 - 13:30</td>
                    <td class="sched_speaker">
                        <strong>Lunch</strong>
                    </td>
                </tr>
                <tr>
                    <td class="sched_time">13:30 - 14:00</td>
                    <td class="sched_speaker">
                        <strong>Speaker 4</strong>

                    </td>
                </tr>
                <tr>
                    <td class="sched_time">14:00 - 14:30</td>
                    <td class="sched_speaker">
                        <strong>Speaker 5</strong>

                    </td>
                </tr>
                <tr>
                    <td class="sched_time">14:30 - 15:00</td>
                    <td class="sched_speaker">
                        <strong>Speaker 6</strong>

                    </td>
                </tr>
                <tr>
                    <td class="sched_time">15:00 - 15:30</td>
                    <td class="sched_speaker">
                        <strong>Coffee Break</strong>
                    </td>
                </tr>
                <tr>
                    <td class="sched_time">15:30 - 16:00</td>
                    <td class="sched_speaker">
                        <strong>Speaker 7</strong>

                    </td>
                </tr>
                <tr>
                    <td class="sched_time">16:00 - 16:45</td>
                    <td class="sched_speaker">
                        <strong>Panel</strong>
                    </td>
                </tr>
                <tr>
                    <td class="sched_time">16:45 - 17:00</td>
                    <td class="sched_speaker">
                        <strong>Closing Remarks</strong>
                    </td>
                </tr>
                <tr>
                    <td class="sched_time">17:00</td>
                    <td class="sched_speaker">
                        <strong>End</strong>
                    </td>
                </tr>
            </table>
        </section>
        <section id="cfp" class="section">
            <h2>Call for Posters</h2>

            <p>
                We invite the submission of posters for the <strong>Bridging Humanoid Robotics and Foundation
                    Models: Embodied Intelligence and AI Integration</strong> workshop at Humanoids 2025. We welcome
                posters that align with the theme of the workshop, including but not limited to topics such as
                large-scale models for robotics, vision-language models in humanoids, embodied AI, human-robot
                interaction, and safe and scalable robot learning.
            </p>
            <p>
                Each poster submission may optionally be accompanied by a <strong>short paper (up to 4 pages,
                    excluding references)</strong>. Submissions should be sent via email to <a
                    href="mailto:dionis.totsila@inria.fr">dionis.totsila@inria.fr</a> with the subject line:
                <code> [HUMANOIDS 2025 - Workshop] Poster Submission</code>.
            </p>
            <p>
                <strong>Submission Deadline:</strong> <u>September 14, 2025 (23:59 AoE)</u> <s>September 2, 2025 (23:59 AoE)</s>
            </p>
            <p>
                Accepted posters will be given a <strong>spotlight presentation slot</strong> and featured in our
                <strong>interactive poster session</strong>, which will take place <em>immediately before and during
                    the coffee break</em>. This is a valuable opportunity to showcase ongoing work, receive
                feedback, and network with researchers working at the intersection of humanoid robotics and
                foundation models.
            </p>
        </section>


        <section id="contact" class="section">
            <h2>Contact</h2>
            <div class="contact-card">
                <p>
                    For any inquiries related to the workshop, submissions, or participation,
                    feel free to reach out to us at:
                </p>
                <p>
                    <strong>Email:</strong>
                    <a href="mailto:dionis.totsila@inria.fr">dionis.totsila@inria.fr</a>
                </p>
                <p>
                    We look forward to hearing from you!
                </p>
            </div>
        </section>

        <section class="sponsors-banner">
            <div class="sponsors-container">
                <!-- <p class="sponsors-text">Supported by</p> -->
                <div class="sponsor-logos">
                    <img src="assets/inria_logo.png" alt="Inria Logo" />
                    <img src="assets/kit_logo.png" alt="KIT Logo" />
                    <img src="assets/deepmind_logo.png" alt="Google DeepMind Logo" />
                    <img src="assets/eurobin_logo.png" alt="Eurobin Logo">
                </div>
                <!-- <div class="sponsor-logos">

                </div> -->
            </div>
        </section>

        <div id="cfp-banner" class="cfp-banner">
            📢 Call for Posters is still OPEN (Extended Sumbission Deadline)!
            <a href="#cfp" class="cfp-link">Submit your poster here</a>
            <button id="cfp-close-btn" class="cfp-close-btn" aria-label="Close notification">&times;</button>
        </div>
    </main>
    <!-- <footer>
        <p>&copy; 2025 Humanoids Workshop · All rights reserved</p>
    </footer> -->

    <script src="script.js"></script>
</body>

</html>